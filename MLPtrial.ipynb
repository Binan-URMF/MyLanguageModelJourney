{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c5be17e5-c88b-4fee-8753-8ba5394d2d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "words = open('/Users/ezelbayraktar/Documents/DL-NLP/MyLanguageModelJourney/names.txt','r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c78f6ccb-e00e-4dc7-bd08-8db176b496fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting chars \n",
    "chars = sorted(list(set(''.join(words))))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6b21a6b4-3350-4f04-8eee-717f6ae1b195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## implementing a dictionary to enum chars\n",
    "ctoi={}\n",
    "ctoi['.'] = 0\n",
    "i = 1\n",
    "for char in chars:\n",
    "    # i do not check if char is in ctoi since chars is already a set so no dupes\n",
    "    # so it is not possible that char is added to ctos twice\n",
    "    ctoi[char] = i\n",
    "    i+=1\n",
    "ctoi['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4ff0bb09-b2c0-4353-8970-b52c1a437e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## implementing a dictionary to char nums\n",
    "\n",
    "## just flipping ctoi since itoc is just the same but with keys and values exchanged\n",
    "itoc = {value: key for key, value in ctoi.items()}\n",
    "itoc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7a68f458-03ed-46d8-884c-d4c159b74d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      ". . .  >>  e\n",
      ". . e  >>  m\n",
      ". e m  >>  m\n",
      "e m m  >>  a\n",
      "m m a  >>  .\n",
      "olivia\n",
      ". . .  >>  o\n",
      ". . o  >>  l\n",
      ". o l  >>  i\n",
      "o l i  >>  v\n",
      "l i v  >>  i\n",
      "i v i  >>  a\n",
      "v i a  >>  .\n",
      "ava\n",
      ". . .  >>  a\n",
      ". . a  >>  v\n",
      ". a v  >>  a\n",
      "a v a  >>  .\n",
      "isabella\n",
      ". . .  >>  i\n",
      ". . i  >>  s\n",
      ". i s  >>  a\n",
      "i s a  >>  b\n",
      "s a b  >>  e\n",
      "a b e  >>  l\n",
      "b e l  >>  l\n",
      "e l l  >>  a\n",
      "l l a  >>  .\n",
      "sophia\n",
      ". . .  >>  s\n",
      ". . s  >>  o\n",
      ". s o  >>  p\n",
      "s o p  >>  h\n",
      "o p h  >>  i\n",
      "p h i  >>  a\n",
      "h i a  >>  .\n"
     ]
    }
   ],
   "source": [
    "## building ...\n",
    "import torch\n",
    "gram = 3\n",
    "X,Y = [],[]\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    grams = [0]*gram\n",
    "    for ch in w+'.':\n",
    "        cai = ctoi[ch] ## cai stands for character as integer\n",
    "        X.append(grams)\n",
    "        Y.append(cai)\n",
    "        print(itoc[grams[0]],itoc[grams[1]],itoc[grams[2]],\" >> \",itoc[cai])\n",
    "        ##print(ch,cai)\n",
    "        grams = grams[1:] + [cai]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d80a8205-a0a5-4a8a-9c0c-37cbf5fa3ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "79143f63-27c4-4957-a958-2854988146be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "61afd382-93e2-444e-9faf-14e3cc933d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , X.dtype , Y.shape , Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c057ac80-ef7c-44f9-8e2a-5092ba34a2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3736e+00,  3.9266e-01],\n",
       "        [ 1.0474e+00,  5.9269e-01],\n",
       "        [ 6.2265e-02, -8.5668e-01],\n",
       "        [-2.8596e-01,  2.6313e-01],\n",
       "        [ 1.7229e-01,  2.5927e-01],\n",
       "        [-1.0883e-03, -3.6440e-01],\n",
       "        [-7.4800e-01,  6.9759e-01],\n",
       "        [-2.2528e+00, -2.1919e-01],\n",
       "        [ 7.0076e-01, -1.1138e+00],\n",
       "        [-8.8191e-02, -1.0446e+00],\n",
       "        [-1.3928e+00, -9.6845e-04],\n",
       "        [ 1.2695e+00, -9.9722e-01],\n",
       "        [-9.8367e-02,  7.9659e-01],\n",
       "        [ 1.2109e+00, -2.0763e+00],\n",
       "        [-1.7025e+00,  7.6926e-01],\n",
       "        [-2.0471e-01,  1.9653e-01],\n",
       "        [ 5.4901e-01,  2.1528e+00],\n",
       "        [ 1.4497e+00,  1.7131e+00],\n",
       "        [ 9.5621e-01,  1.9685e+00],\n",
       "        [ 6.2519e-01,  2.4074e-01],\n",
       "        [ 8.3296e-01,  4.6716e-01],\n",
       "        [-3.4052e-01, -3.2161e-01],\n",
       "        [ 3.2996e-01, -1.2689e+00],\n",
       "        [ 8.2533e-02,  6.1379e-01],\n",
       "        [-3.4519e-01, -9.7349e-01],\n",
       "        [-3.5902e-01, -3.3153e-01],\n",
       "        [-5.4774e-01,  5.5413e-01],\n",
       "        [-1.2282e+00, -7.9278e-01],\n",
       "        [ 1.3326e-01, -1.7031e+00],\n",
       "        [-7.1832e-01,  6.9303e-01],\n",
       "        [ 5.1244e-01, -2.8459e-01],\n",
       "        [-9.5259e-01,  5.5688e-01]], device='mps:0')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choosing gpu as computational device if gpu is available\n",
    "# since we are working with small data this step is not necessary indeed\n",
    "# but i own the repo and do whatever i want... just joking doing it for fun im really stressed out\n",
    "\n",
    "\n",
    "# MPS: Metal Performance Shaders --> for Mac devices with M chips\n",
    "# CUDA: For device with cuda support\n",
    "# CPU: General case\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "generator = torch.Generator(device=device)\n",
    "#seed = 20040324\n",
    "#generator.manual_seed(seed)\n",
    "\n",
    "rows = 27 #  english chars + the dot\n",
    "dimension = 2 # dimensions for each char\n",
    "params = torch.randn(rows, dimension, generator=generator, device=device)\n",
    "params\n",
    "# params are the dimension values our model assigns to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7919b84e-b7cc-4f0d-a2f3-80a609b1f645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0623, -0.8567], device='mps:0')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## experimenting with indecis\n",
    "params[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "16c1dd3a-636a-48e1-bc07-330b4b8bd240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 22,  9])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9ff2f94a-432c-4726-8abc-fe5fc5e60f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0882, -1.0446],\n",
       "        [ 0.3300, -1.2689],\n",
       "        [-0.0882, -1.0446]], device='mps:0')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[X[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "df2b679c-3afb-459d-a59e-9759809dbe20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[X[10]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "251671a0-f5ac-45e5-908c-961d40e9987c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7e11a6b9-01e9-4d56-9233-38ed234523a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [-1.0883e-03, -3.6440e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.0883e-03, -3.6440e-01],\n",
       "         [ 1.2109e+00, -2.0763e+00]],\n",
       "\n",
       "        [[-1.0883e-03, -3.6440e-01],\n",
       "         [ 1.2109e+00, -2.0763e+00],\n",
       "         [ 1.2109e+00, -2.0763e+00]],\n",
       "\n",
       "        [[ 1.2109e+00, -2.0763e+00],\n",
       "         [ 1.2109e+00, -2.0763e+00],\n",
       "         [ 1.0474e+00,  5.9269e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [-2.0471e-01,  1.9653e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-2.0471e-01,  1.9653e-01],\n",
       "         [-9.8367e-02,  7.9659e-01]],\n",
       "\n",
       "        [[-2.0471e-01,  1.9653e-01],\n",
       "         [-9.8367e-02,  7.9659e-01],\n",
       "         [-8.8191e-02, -1.0446e+00]],\n",
       "\n",
       "        [[-9.8367e-02,  7.9659e-01],\n",
       "         [-8.8191e-02, -1.0446e+00],\n",
       "         [ 3.2996e-01, -1.2689e+00]],\n",
       "\n",
       "        [[-8.8191e-02, -1.0446e+00],\n",
       "         [ 3.2996e-01, -1.2689e+00],\n",
       "         [-8.8191e-02, -1.0446e+00]],\n",
       "\n",
       "        [[ 3.2996e-01, -1.2689e+00],\n",
       "         [-8.8191e-02, -1.0446e+00],\n",
       "         [ 1.0474e+00,  5.9269e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [ 1.0474e+00,  5.9269e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [ 1.0474e+00,  5.9269e-01],\n",
       "         [ 3.2996e-01, -1.2689e+00]],\n",
       "\n",
       "        [[ 1.0474e+00,  5.9269e-01],\n",
       "         [ 3.2996e-01, -1.2689e+00],\n",
       "         [ 1.0474e+00,  5.9269e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [-8.8191e-02, -1.0446e+00]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-8.8191e-02, -1.0446e+00],\n",
       "         [ 6.2519e-01,  2.4074e-01]],\n",
       "\n",
       "        [[-8.8191e-02, -1.0446e+00],\n",
       "         [ 6.2519e-01,  2.4074e-01],\n",
       "         [ 1.0474e+00,  5.9269e-01]],\n",
       "\n",
       "        [[ 6.2519e-01,  2.4074e-01],\n",
       "         [ 1.0474e+00,  5.9269e-01],\n",
       "         [ 6.2265e-02, -8.5668e-01]],\n",
       "\n",
       "        [[ 1.0474e+00,  5.9269e-01],\n",
       "         [ 6.2265e-02, -8.5668e-01],\n",
       "         [-1.0883e-03, -3.6440e-01]],\n",
       "\n",
       "        [[ 6.2265e-02, -8.5668e-01],\n",
       "         [-1.0883e-03, -3.6440e-01],\n",
       "         [-9.8367e-02,  7.9659e-01]],\n",
       "\n",
       "        [[-1.0883e-03, -3.6440e-01],\n",
       "         [-9.8367e-02,  7.9659e-01],\n",
       "         [-9.8367e-02,  7.9659e-01]],\n",
       "\n",
       "        [[-9.8367e-02,  7.9659e-01],\n",
       "         [-9.8367e-02,  7.9659e-01],\n",
       "         [ 1.0474e+00,  5.9269e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [-1.3736e+00,  3.9266e-01],\n",
       "         [ 6.2519e-01,  2.4074e-01]],\n",
       "\n",
       "        [[-1.3736e+00,  3.9266e-01],\n",
       "         [ 6.2519e-01,  2.4074e-01],\n",
       "         [-2.0471e-01,  1.9653e-01]],\n",
       "\n",
       "        [[ 6.2519e-01,  2.4074e-01],\n",
       "         [-2.0471e-01,  1.9653e-01],\n",
       "         [ 5.4901e-01,  2.1528e+00]],\n",
       "\n",
       "        [[-2.0471e-01,  1.9653e-01],\n",
       "         [ 5.4901e-01,  2.1528e+00],\n",
       "         [ 7.0076e-01, -1.1138e+00]],\n",
       "\n",
       "        [[ 5.4901e-01,  2.1528e+00],\n",
       "         [ 7.0076e-01, -1.1138e+00],\n",
       "         [-8.8191e-02, -1.0446e+00]],\n",
       "\n",
       "        [[ 7.0076e-01, -1.1138e+00],\n",
       "         [-8.8191e-02, -1.0446e+00],\n",
       "         [ 1.0474e+00,  5.9269e-01]]], device='mps:0')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we still have the gram table actually but each character in each gram is repsrented with dimenstional params\n",
    "params[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "20e9174e-38ee-433d-a389-1b5a139a7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = params[X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e86bc4fd-e10c-4c1f-965c-f89f2aac7b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4057,  0.1224,  0.7896,  ...,  0.5229, -2.4942, -0.9010],\n",
       "        [-0.8378,  0.9826,  1.2608,  ...,  0.3411, -0.3754, -1.1941],\n",
       "        [-0.3678,  1.8012,  0.5007,  ..., -1.2406, -0.9563, -1.8918],\n",
       "        [ 0.7669,  0.0492, -0.7167,  ...,  0.4146, -3.5071, -0.4178],\n",
       "        [-0.1586,  0.3480, -0.3436,  ..., -0.6795, -1.2412, -0.3884],\n",
       "        [-1.1859, -1.6101, -2.1689,  ..., -2.0254, -0.2208,  2.0707]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#layer 1\n",
    "inputNumberLayer1 = (params[X].shape)[2]*(params[X].shape)[1] # input nummber is equal to (grams count) * (dimensions)\n",
    "inputNumberLayer1\n",
    "neuronsLayer1 = 200 # matter of choice CAUTION: too much neurons may cause overfitting\n",
    "\n",
    "W1 = torch.randn(inputNumberLayer1, neuronsLayer1, generator=generator, device=device) # first layer's weights\n",
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c2cad3e3-b3c3-4ee8-859a-0c755ffe7767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 200])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "81f6517b-55b7-4e73-9c31-e37d5ed6cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = torch.randn(100,generator=generator, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a7a715da-9ab3-40dc-9275-abe32106358e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 200]), torch.Size([32, 3, 2]))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape, emb.shape #hmmmm.. problem! cannot matrix multiply because of dimensions not holding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2ff8d079-d18b-4631-8284-d4399602e8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01, -1.3736e+00,\n",
       "          3.9266e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01, -1.0883e-03,\n",
       "         -3.6440e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.0883e-03, -3.6440e-01,  1.2109e+00,\n",
       "         -2.0763e+00],\n",
       "        [-1.0883e-03, -3.6440e-01,  1.2109e+00, -2.0763e+00,  1.2109e+00,\n",
       "         -2.0763e+00],\n",
       "        [ 1.2109e+00, -2.0763e+00,  1.2109e+00, -2.0763e+00,  1.0474e+00,\n",
       "          5.9269e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01, -1.3736e+00,\n",
       "          3.9266e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01, -2.0471e-01,\n",
       "          1.9653e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -2.0471e-01,  1.9653e-01, -9.8367e-02,\n",
       "          7.9659e-01],\n",
       "        [-2.0471e-01,  1.9653e-01, -9.8367e-02,  7.9659e-01, -8.8191e-02,\n",
       "         -1.0446e+00],\n",
       "        [-9.8367e-02,  7.9659e-01, -8.8191e-02, -1.0446e+00,  3.2996e-01,\n",
       "         -1.2689e+00],\n",
       "        [-8.8191e-02, -1.0446e+00,  3.2996e-01, -1.2689e+00, -8.8191e-02,\n",
       "         -1.0446e+00],\n",
       "        [ 3.2996e-01, -1.2689e+00, -8.8191e-02, -1.0446e+00,  1.0474e+00,\n",
       "          5.9269e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01, -1.3736e+00,\n",
       "          3.9266e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01,  1.0474e+00,\n",
       "          5.9269e-01],\n",
       "        [-1.3736e+00,  3.9266e-01,  1.0474e+00,  5.9269e-01,  3.2996e-01,\n",
       "         -1.2689e+00],\n",
       "        [ 1.0474e+00,  5.9269e-01,  3.2996e-01, -1.2689e+00,  1.0474e+00,\n",
       "          5.9269e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01, -1.3736e+00,\n",
       "          3.9266e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01, -8.8191e-02,\n",
       "         -1.0446e+00],\n",
       "        [-1.3736e+00,  3.9266e-01, -8.8191e-02, -1.0446e+00,  6.2519e-01,\n",
       "          2.4074e-01],\n",
       "        [-8.8191e-02, -1.0446e+00,  6.2519e-01,  2.4074e-01,  1.0474e+00,\n",
       "          5.9269e-01],\n",
       "        [ 6.2519e-01,  2.4074e-01,  1.0474e+00,  5.9269e-01,  6.2265e-02,\n",
       "         -8.5668e-01],\n",
       "        [ 1.0474e+00,  5.9269e-01,  6.2265e-02, -8.5668e-01, -1.0883e-03,\n",
       "         -3.6440e-01],\n",
       "        [ 6.2265e-02, -8.5668e-01, -1.0883e-03, -3.6440e-01, -9.8367e-02,\n",
       "          7.9659e-01],\n",
       "        [-1.0883e-03, -3.6440e-01, -9.8367e-02,  7.9659e-01, -9.8367e-02,\n",
       "          7.9659e-01],\n",
       "        [-9.8367e-02,  7.9659e-01, -9.8367e-02,  7.9659e-01,  1.0474e+00,\n",
       "          5.9269e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01, -1.3736e+00,\n",
       "          3.9266e-01],\n",
       "        [-1.3736e+00,  3.9266e-01, -1.3736e+00,  3.9266e-01,  6.2519e-01,\n",
       "          2.4074e-01],\n",
       "        [-1.3736e+00,  3.9266e-01,  6.2519e-01,  2.4074e-01, -2.0471e-01,\n",
       "          1.9653e-01],\n",
       "        [ 6.2519e-01,  2.4074e-01, -2.0471e-01,  1.9653e-01,  5.4901e-01,\n",
       "          2.1528e+00],\n",
       "        [-2.0471e-01,  1.9653e-01,  5.4901e-01,  2.1528e+00,  7.0076e-01,\n",
       "         -1.1138e+00],\n",
       "        [ 5.4901e-01,  2.1528e+00,  7.0076e-01, -1.1138e+00, -8.8191e-02,\n",
       "         -1.0446e+00],\n",
       "        [ 7.0076e-01, -1.1138e+00, -8.8191e-02, -1.0446e+00,  1.0474e+00,\n",
       "          5.9269e-01]], device='mps:0')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " emb = torch.cat(torch.unbind(emb,1),1)\n",
    " emb\n",
    "\n",
    "## MY EXPLANATION:\n",
    "\n",
    "## here torch.unbind(emb,1) seperates our tensor across the first dimension (columns) and we get three (32,2) tensors. \n",
    "## i was confused when i learned about it at first so here is the explanation. \n",
    "## imagine a cube of 32 rows , 3 columns, and 2 layers(depth) we seperate the cube across columns so we are left with three slices\n",
    "## each of 32 row and 2 depth layers. we concatenate the slices now across the first dimension of each. \n",
    "## here is the key! the first dimension now is what was depth layers before. the 2 is now the columns. so when we contatenate\n",
    "## across the first dimension we combine three two columns to get six columns. the first two are the columns of the first slice\n",
    "## and the depth layers of the first column we had initially.\n",
    "\n",
    "## GPT EDITED EXPLANATION\n",
    "\n",
    "# Imagine 'emb' as a 3D tensor with a shape of (32, 3, 2), where\n",
    "# 32 represents the depth (layers), 3 represents the rows, and 2 represents the columns.\n",
    "\n",
    "# Applying torch.unbind(emb, 1) splits 'emb' across the rows (since 1 indicates rows here),\n",
    "# resulting in 3 tensors, each with a shape of (32, 2) - they have 32 layers (depth) and 2 columns,\n",
    "# but only 1 row because we've split along the rows.\n",
    "\n",
    "# These 3 tensors are like 3 flat sheets from our initial cube:\n",
    "# 1. The first sheet contains the first row from every layer.\n",
    "# 2. The second sheet contains the second row from every layer.\n",
    "# 3. The third sheet contains the third row from every layer.\n",
    "\n",
    "# Now, torch.cat(...) will concatenate these 3 sheets along the first dimension (rows),\n",
    "# effectively stacking them back to form the original structure but now as separate tensors.\n",
    "\n",
    "# After concatenation, we have a tensor that resembles the original 'emb' in shape,\n",
    "# having 32 layers (depth), 3 rows, and 2 columns.\n",
    "# The first dimension now refers to the rows, the second to the layers (depth), and the third to columns.\n",
    "# This reassembled structure maintains the original depth and columns but has reorganized the rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f54a92-4e1a-42d9-8942-c7583594a127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
